{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c603a4",
   "metadata": {},
   "source": [
    "# üéØ CoLA Dataset Trainer - Gradio Interface\n",
    "\n",
    "**Interactive notebook for launching the Google CoLA (Corpus of Linguistic Acceptability) training interface**\n",
    "\n",
    "This notebook provides an easy way to:\n",
    "- Install required dependencies\n",
    "- Launch the Gradio web interface\n",
    "- Monitor training progress\n",
    "- Access the interface from any device\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ec526",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies\n",
    "\n",
    "First, let's install all the required packages for the CoLA trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q gradio torch transformers datasets scikit-learn pandas numpy tqdm evaluate accelerate\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8fd1d",
   "metadata": {},
   "source": [
    "## üîß Step 2: Check System Information\n",
    "\n",
    "Let's check what hardware we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"üñ•Ô∏è  System Information:\")\n",
    "print(f\"   Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"   Python: {platform.python_version()}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   CUDA Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   Using CPU for training\")\n",
    "\n",
    "print(f\"\\nüìÅ Current Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3e2d6",
   "metadata": {},
   "source": [
    "## üìä Step 3: Create Sample CoLA Dataset (Optional)\n",
    "\n",
    "If you don't have a CoLA dataset ready, let's create a sample one for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43290a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create sample CoLA dataset\n",
    "sample_data = [\n",
    "    # Acceptable sentences (label = 1)\n",
    "    {\"sentence\": \"The cat sat on the mat.\", \"label\": 1},\n",
    "    {\"sentence\": \"She quickly ran to the store.\", \"label\": 1},\n",
    "    {\"sentence\": \"I think that he will come tomorrow.\", \"label\": 1},\n",
    "    {\"sentence\": \"The book on the table is mine.\", \"label\": 1},\n",
    "    {\"sentence\": \"We went to the movies last night.\", \"label\": 1},\n",
    "    {\"sentence\": \"The dog barked loudly at the stranger.\", \"label\": 1},\n",
    "    {\"sentence\": \"Can you help me with this problem?\", \"label\": 1},\n",
    "    {\"sentence\": \"The weather is beautiful today.\", \"label\": 1},\n",
    "    {\"sentence\": \"She speaks three languages fluently.\", \"label\": 1},\n",
    "    {\"sentence\": \"The children are playing in the garden.\", \"label\": 1},\n",
    "    \n",
    "    # Unacceptable sentences (label = 0)\n",
    "    {\"sentence\": \"Cat the sat mat on the.\", \"label\": 0},\n",
    "    {\"sentence\": \"Quickly she to store the ran.\", \"label\": 0},\n",
    "    {\"sentence\": \"Think I that tomorrow will he come.\", \"label\": 0},\n",
    "    {\"sentence\": \"Book the table on mine is the.\", \"label\": 0},\n",
    "    {\"sentence\": \"Movies we the to last went night.\", \"label\": 0},\n",
    "    {\"sentence\": \"Barked dog the loudly stranger at the.\", \"label\": 0},\n",
    "    {\"sentence\": \"Help can with me you problem this?\", \"label\": 0},\n",
    "    {\"sentence\": \"Weather beautiful the today is.\", \"label\": 0},\n",
    "    {\"sentence\": \"Languages three speaks fluently she.\", \"label\": 0},\n",
    "    {\"sentence\": \"Playing children the garden in are the.\", \"label\": 0},\n",
    "]\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save as CSV\n",
    "df = pd.DataFrame(sample_data)\n",
    "csv_path = data_dir / \"sample_cola_dataset.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Save as JSON\n",
    "json_path = data_dir / \"sample_cola_dataset.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(sample_data, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Sample CoLA datasets created:\")\n",
    "print(f\"   üìÅ CSV: {csv_path}\")\n",
    "print(f\"   üìÅ JSON: {json_path}\")\n",
    "print(f\"\\nüìä Dataset Info:\")\n",
    "print(f\"   Total samples: {len(sample_data)}\")\n",
    "print(f\"   Acceptable: {sum(1 for x in sample_data if x['label'] == 1)}\")\n",
    "print(f\"   Unacceptable: {sum(1 for x in sample_data if x['label'] == 0)}\")\n",
    "\n",
    "# Display preview\n",
    "print(\"\\nüìã Dataset Preview:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdf180",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Launch Gradio Interface\n",
    "\n",
    "Now let's launch the main Gradio interface for CoLA training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CoLA trainer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add current directory to path to import our module\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Import the gradio interface\n",
    "try:\n",
    "    from gradio_cola_trainer import create_interface, cola_trainer\n",
    "    print(\"‚úÖ CoLA trainer module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing CoLA trainer: {e}\")\n",
    "    print(\"Make sure gradio_cola_trainer.py is in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26610bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "print(\"üöÄ Launching Gradio Interface...\")\n",
    "print(\"\\nüì± The interface will be available at:\")\n",
    "print(\"   ‚Ä¢ Local: http://localhost:7860\")\n",
    "print(\"   ‚Ä¢ Network: Available to other devices on your network\")\n",
    "print(\"   ‚Ä¢ Public: Shareable link will be generated\\n\")\n",
    "\n",
    "# Create and launch interface\n",
    "interface = create_interface()\n",
    "\n",
    "# Launch with custom settings for notebook environment\n",
    "interface.launch(\n",
    "    server_name=\"0.0.0.0\",  # Allow external access\n",
    "    server_port=7860,       # Standard port\n",
    "    share=True,             # Create public link\n",
    "    debug=False,            # Disable debug in notebook\n",
    "    show_error=True,        # Show errors in interface\n",
    "    inline=False            # Open in new tab/window\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77474c",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Quick Training Guide\n",
    "\n",
    "Once the interface is launched, follow these steps:\n",
    "\n",
    "### 1. **Upload Dataset** üìÇ\n",
    "- Go to the \"Dataset Upload\" tab\n",
    "- Upload your CSV, TSV, or JSON file with CoLA format\n",
    "- Or use the sample dataset we created: `data/sample_cola_dataset.csv`\n",
    "- Verify the dataset preview looks correct\n",
    "\n",
    "### 2. **Configure Training** ‚öôÔ∏è\n",
    "- Go to the \"Model Training\" tab\n",
    "- Choose model size:\n",
    "  - **Small**: Fast, good for testing\n",
    "  - **Base**: Balanced speed/accuracy\n",
    "  - **Large**: Best accuracy, slower\n",
    "- Adjust parameters as needed\n",
    "- Click \"Start Training\"\n",
    "\n",
    "### 3. **Test Model** üß™\n",
    "- Go to the \"Model Testing\" tab\n",
    "- Enter sentences to test (one per line)\n",
    "- Click \"Test Sentences\" to see predictions\n",
    "\n",
    "### 4. **Get Help** ‚ùì\n",
    "- Check the \"Help\" tab for detailed instructions\n",
    "- Find tips for better training results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18b386",
   "metadata": {},
   "source": [
    "## üìä Step 6: Monitor Training (Optional)\n",
    "\n",
    "You can monitor training progress and system resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def monitor_system(duration_minutes=5):\n",
    "    \"\"\"Monitor system resources during training\"\"\"\n",
    "    end_time = time.time() + (duration_minutes * 60)\n",
    "    \n",
    "    while time.time() < end_time:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # CPU and Memory\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        memory = psutil.virtual_memory()\n",
    "        \n",
    "        print(\"üìä System Monitoring:\")\n",
    "        print(f\"   CPU Usage: {cpu_percent:.1f}%\")\n",
    "        print(f\"   Memory Usage: {memory.percent:.1f}% ({memory.used / 1e9:.1f}GB / {memory.total / 1e9:.1f}GB)\")\n",
    "        \n",
    "        # GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "            gpu_allocated = torch.cuda.memory_allocated()\n",
    "            gpu_cached = torch.cuda.memory_reserved()\n",
    "            \n",
    "            print(f\"   GPU Memory: {gpu_allocated / 1e9:.1f}GB allocated, {gpu_cached / 1e9:.1f}GB cached\")\n",
    "            print(f\"   GPU Usage: {(gpu_allocated / gpu_memory * 100):.1f}%\")\n",
    "        \n",
    "        print(f\"\\n‚è∞ Monitoring for {duration_minutes} minutes...\")\n",
    "        print(\"   (Stop this cell to end monitoring)\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "# Uncomment to start monitoring\n",
    "# monitor_system(duration_minutes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdd6f3",
   "metadata": {},
   "source": [
    "## üîÑ Step 7: Restart Interface (If Needed)\n",
    "\n",
    "If you need to restart the interface with different settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758480d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop current interface (if running)\n",
    "try:\n",
    "    interface.close()\n",
    "    print(\"‚úÖ Previous interface closed\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è  No interface was running\")\n",
    "\n",
    "# Create new interface\n",
    "interface = create_interface()\n",
    "\n",
    "# Launch with new settings\n",
    "interface.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7861,  # Different port if 7860 is busy\n",
    "    share=True,\n",
    "    debug=False,\n",
    "    inline=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff1ffd",
   "metadata": {},
   "source": [
    "## üìÅ Step 8: File Management\n",
    "\n",
    "Useful commands for managing your training files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# List all files in current directory\n",
    "print(\"üìÅ Current Directory Contents:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    if os.path.isdir(item):\n",
    "        print(f\"   üìÇ {item}/\")\n",
    "    else:\n",
    "        print(f\"   üìÑ {item}\")\n",
    "\n",
    "# List data files\n",
    "print(\"\\nüìä Data Files:\")\n",
    "data_files = glob.glob(\"data/*\")\n",
    "for file in sorted(data_files):\n",
    "    print(f\"   üìÑ {file}\")\n",
    "\n",
    "# List any trained models\n",
    "print(\"\\nü§ñ Trained Models:\")\n",
    "model_dirs = glob.glob(\"cola_model_*\")\n",
    "if model_dirs:\n",
    "    for model_dir in sorted(model_dirs):\n",
    "        print(f\"   üéØ {model_dir}\")\n",
    "else:\n",
    "    print(\"   No trained models found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e3bd3",
   "metadata": {},
   "source": [
    "## üßπ Step 9: Cleanup (Optional)\n",
    "\n",
    "Clean up temporary files and free memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "def cleanup_session():\n",
    "    \"\"\"Clean up memory and temporary files\"\"\"\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"‚úÖ GPU memory cleared\")\n",
    "    \n",
    "    # Garbage collection\n",
    "    gc.collect()\n",
    "    print(\"‚úÖ Garbage collection completed\")\n",
    "    \n",
    "    # Clear model from trainer\n",
    "    try:\n",
    "        cola_trainer.model = None\n",
    "        cola_trainer.tokenizer = None\n",
    "        cola_trainer.trainer = None\n",
    "        print(\"‚úÖ Model cleared from memory\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è  No model to clear\")\n",
    "\n",
    "# Uncomment to run cleanup\n",
    "# cleanup_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0783a43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ You're All Set!\n",
    "\n",
    "The Gradio interface is now running and ready for CoLA dataset training. \n",
    "\n",
    "**Key Features Available:**\n",
    "- ‚úÖ Dataset upload and validation\n",
    "- ‚úÖ Interactive training configuration\n",
    "- ‚úÖ Real-time model testing\n",
    "- ‚úÖ Comprehensive help documentation\n",
    "- ‚úÖ Public sharing capabilities\n",
    "\n",
    "**Next Steps:**\n",
    "1. Upload your CoLA dataset or use the sample we created\n",
    "2. Configure training parameters\n",
    "3. Start training your model\n",
    "4. Test the trained model on new sentences\n",
    "\n",
    "Happy training! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
